{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DibiaCorp85/fine-tuning_nllb-200_600M/blob/main/_Fine_Tuning_En_Yo_LaTn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46HOKOHDsASy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMTxEDN6sEjk"
      },
      "source": [
        "## **Install Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrAh2JE3sEf8",
        "outputId": "84193999-acb9-445d-d6a1-e55cba0d1bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.3/800.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m995.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for literalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for syncer (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet chainlit pyngrok datasets transformers evaluate accelerate peft sacrebleu rouge_score bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-abQrgJoUs2"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade fsspec datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y9wq391sEdk"
      },
      "source": [
        "## **Import Core Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7ir1BGVsEa_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import requests\n",
        "from torch.optim import AdamW\n",
        "from datasets import (load_dataset,\n",
        "                      concatenate_datasets,\n",
        "                      DatasetDict,\n",
        "                      Dataset,\n",
        "                      get_dataset_config_names,\n",
        "                      Features,\n",
        "                      ClassLabel,\n",
        "                      Value,\n",
        "                      Translation\n",
        "                      )\n",
        "\n",
        "from transformers import (\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from peft import (\n",
        "    TaskType,\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    PeftModel,\n",
        "    PeftConfig,\n",
        ")\n",
        "\n",
        "from huggingface_hub import login\n",
        "from google.colab import drive\n",
        "import getpass\n",
        "from pyngrok import conf, ngrok\n",
        "import subprocess\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB89k0d3sEXI",
        "outputId": "176cb873-8d5b-45e2-9e00-44c2f069d8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to save model and logs\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "save_dir = \"/content/drive/MyDrive/Colab Notebooks/NLLB_200/En-Yo_LaTn\"\n",
        "os.makedirs(save_dir, exist_ok = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGPT4cP7sEUt"
      },
      "source": [
        "## **Load Datasets**\n",
        "\n",
        "English-\"Language\" datasets are loaded from Hugging Face.\n",
        "\n",
        "For this process, the following languages are considered:\n",
        "* Yoruba\n",
        "\n",
        "The following are the datasets are used:\n",
        "\n",
        "* Opus100 containing the above listed languages paired with English language.\n",
        "* UdS-LSV/menyo20k_mt for English-Yoruba pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4wxoGrp5SpN"
      },
      "source": [
        "### **Opus100 Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "6f51aa344264421abeb308260825813c",
            "dc900e37861e424d879de9a5e291bfc2",
            "e4ab017837174d10800ca5c761cf04c3",
            "aea81bdf393f433797a9ea8b25f22a41",
            "b74dfb5872df4dbe9b582832931cd615",
            "f00e8df83dbf41838823d9dd017ea306",
            "5106996b897748339fe9b585eb350b99",
            "b7e20eb510cd489485555946abed9af2",
            "ea0110f311c349ac821d10d5e6dc39d2",
            "52454368d13b4e6d831a47ad2608720c",
            "3ff29d6ba19e4c6c924e1113cb777781"
          ]
        },
        "id": "yC2sCb91sERW",
        "outputId": "9044ca20-9278-4260-aa09-d40551352c85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f51aa344264421abeb308260825813c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/65.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The En-Yo language pair is present in Opus100 dataset:\n",
            " - en-yo (Yoruba)\n"
          ]
        }
      ],
      "source": [
        "login(\"hf access token key\")\n",
        "\n",
        "# List of desired target languages ISO codes(to pair with English Language)\n",
        "target_language = {\"yo\" : \"Yoruba\"}\n",
        "\n",
        "source_language = \"en\" # Fixed source language\n",
        "\n",
        "desired_pairs = [f\"{source_language}-{tgt}\" for tgt in target_language]\n",
        "\n",
        "# Fetch all configurations from Opus100\n",
        "available_configs = get_dataset_config_names(\"opus100\")\n",
        "\n",
        "# Filter those that exist in Opus100\n",
        "present_pairs = [pair for pair in desired_pairs if pair in available_configs]\n",
        "missing_pairs = [pair for pair in desired_pairs if pair not in available_configs]\n",
        "\n",
        "# Print results\n",
        "print(\" The En-Yo language pair is present in Opus100 dataset:\")\n",
        "for pair in present_pairs:\n",
        "    print(f\" - {pair} ({target_language[pair.split('-')[1]]})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMTkEkrisEPK"
      },
      "source": [
        "#### **Load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "3bb5c438f38e49ad8782b98ae57b9f41",
            "30f6798253b641c1af9545194659c973",
            "f75f12eda78c4299a361c78ffd37ee99",
            "2abb2e3ad0a846eba09e5404ee874c73",
            "1dc65d3734bd4f1a85302fb0fe014eaf",
            "acadc3fd23114f768dd150ebd3003db3",
            "15b6dec81b5f4383b7c2f4bd28942d9a",
            "3b79ac04868941da87a28b939b6586a6",
            "7ac34431a1d44e0985cb95119a73671b",
            "0348e87a1b5c4b92872b348a440d0d5d",
            "cacd92cd902142bab5dce964ac7fcc5b",
            "65aaaf72bad44085b9a4a7666c3b8dad",
            "baebeb0fd35b4829a7109c55d9e9efbe",
            "9b93f7fcea85488b9d138e6c65b5c9a3",
            "7a108d2d7b404acf8bed1547d1cc4a2f",
            "34a3101655804f8f9790c1b7fce4eb2b",
            "7fb4e6a8f44a49bb846012d1c7e05ab4",
            "ae134b57f8084d18ae4744405e49d8b5",
            "3466603c73af4d0c92ec6ac97c2aea65",
            "621b9a249b8f439999bf6bbba28590c2",
            "e8ca4c58797b4d34bed2cd2d55a349e3",
            "041fb6937a9c459898bc318f8d8c7c4e"
          ]
        },
        "id": "RLOJlAoOsEM2",
        "outputId": "3b1ffb92-b984-45f6-cf24-a2d8d5ab2ed0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bb5c438f38e49ad8782b98ae57b9f41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/391k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65aaaf72bad44085b9a4a7666c3b8dad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/10375 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English-Yoruba language pair downloaded!\n"
          ]
        }
      ],
      "source": [
        "# English-Yoruba\n",
        "selected_language = [\"yo\"]\n",
        "\n",
        "if \"yo\" in selected_language:\n",
        "    try:\n",
        "        opus_en_yo = load_dataset(\"opus100\", \"en-yo\")\n",
        "        print(\"English-Yoruba language pair downloaded!\")\n",
        "    except Exception as e:\n",
        "        print(\"Failed to download English-Yoruba:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEkLdJY5sELG"
      },
      "source": [
        "### **UdS-LSV/menyo20k_mt for English-Yoruba Pairs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "84184d5ee24d4f1b9763d000b9951c31",
            "b4ed754795f04c4fa19864cab687eb23",
            "c1272d90246345c89376083c1a46f4f9",
            "badf454bd8f04cae924c3556f6505f96",
            "b1a623c8703b4e43b7c8edf586cc17b5",
            "b38fe051df26483ab7c6318000a76910",
            "f1f5e75b99b44c16b8b39e3b88e29626",
            "4eb64397d6c44d169e481e329be6c20d",
            "d55da13e5dac432781852cee8d12723c",
            "df534aa94e5442f28122f35619d4da8b",
            "ba73a0ff2155405c8c0bd1f27a47253a",
            "ff06aac71e324cac8aeb17e642b55c4c",
            "1eed25a0f75b461895b629740ccf7acc",
            "939c6d0e96164d909a3115d019fd2e24",
            "7c66fc06939e46ffbdd281dfb3b0c02b",
            "580b47bed8f44e53bb73479954727f07",
            "7f11ba6984dd43bf99101f9396f6177c",
            "62e0fc2317e8439d809b6f29687fc627",
            "33f37700df1e4089b1e5b52a1d739207",
            "42ac2367728f40b9875abb09c64bebd7",
            "4918563c37724479ad61ded889559ffe",
            "2243bdb808d14c4eb62e4835b7c33b43",
            "38ea4c9e2de34c06a72dc1ca34ee03b7",
            "8d40b6bbf4314f4bb040a2e20b26e9be",
            "b099a1f1f67c42d9aae2ae92e2122d6b",
            "adc691e2ced3432e953279291c66c1dc",
            "7d0d887abca744d298cd3bed72d18546",
            "cfb5eb04a53045f7b0dca7a4bee690f3",
            "c8b7b26a072b4b4fa9e62ba1d00065d6",
            "114e4c1e834e421182a35421e3ea638d",
            "90607e55df2c465abfb428f6a9a3e33b",
            "1745cec18b92428f928c8c8dd08b4e00",
            "7e5e7ecb4bbc489f9d291851da9ee5f6",
            "452cb13c175944e29d88c16f3ad5808d",
            "6aca17a25b8c4268a3223449fabd3c63",
            "d6220461107e438d9e6d7600bae866bf",
            "c4891fd9f73c40e89a2bffe2badb29f3",
            "100f40d7c8c04571a53bcd431e30b671",
            "049e431666d5495db60a0d80e34ba034",
            "b05d30bf6cd849de932885ac00e88a69",
            "b44163e5225f4d4e82affcef83a89361",
            "b2226bf025ca48988aad668de695199c",
            "230197dd9a624dee8923521499384188",
            "fa73c13c3e2a400789bd05523747caa5",
            "710810670a484ee3844b43e787e39b1a",
            "baa1f3ab536143be97970cddcbabf754",
            "35d2af28dd294c43b5135a50ddc7e723",
            "baac8e64f4fb47e39daa7f9509f96b9f",
            "b0d1ba1b823d4a7cbd892efc188210ce",
            "14fd3dd90ed242ab958bbcdea6e948fe",
            "a09cf3cab7574e12bfa22b652adc7817",
            "e9c6d3982c974bde81ac5b3db1fd723d",
            "ba8a05d7c32147fc8cc901e0bf36ee68",
            "25660e87fe19493dbebff9fd56d12f2e",
            "1d9551e90580437a91708d5f1a65cdd9",
            "8d03863462d043ee87770f3cae7f2648",
            "b1851f1d1c7a4c42833dd234a2c99342",
            "d2070e47e6e2436d9051697c3ed87f3a",
            "cb2606c91122459a810c3fa32aaf0578",
            "cc28766504e84b45a22ec471e0d8b3c7",
            "cb024d2dd05c4aa18c72a32f689050b9",
            "337d704a2a65423888a19f8ef3c3b0d5",
            "f27195b6e90d49aaaa7b085ca5b63a02",
            "7bba14a8716b48a8a1969ef78aeb0ede",
            "08ff31817bfb4bd485b8a649481d836e",
            "f421ba02a1104d6fa2d483249c779220",
            "4f164902e60743aba2927f80085299ac",
            "4b45484a2ef047fbba3d8e089429c385",
            "5206dce23d804fe589c496e7e696acce",
            "860090347e444503ad8b0f675483c8d7",
            "dbea9690c59a4225aad306073ac7e139",
            "55992371d58642e6ba4d8da726418b57",
            "0ec77d132ffa40ff91cafe89f2524e55",
            "34529322c55a41fcbab0a22aa106d23d",
            "ecd472720e664c5e92583d8425247ae8",
            "31947860a3f24a099c494d27afa5b828",
            "3906ac5279dc4e36b0b7b27f7fb098fa",
            "50b56bcbd3194cdb8f8c3060aa12e21e",
            "43242a04a3c44780ab87a0ec62d9da23",
            "0ae6177987034f039cb6a073d57b8e88",
            "c1e0d56e649042329b2ff900779dc199",
            "a10c42bfb37546bda0a8fd83ba36aee3",
            "7db9b3b0332447c18402aa7b1c4ea56f",
            "2546bf6437dc4fedba5c32641c21949b",
            "f2c3e6c54cb34d6a997ec2fb8e34aa6f",
            "4a6d8b6e27d14d1f8cc356f6fe3d3d92",
            "e014c003ed874d51a7c7588416f35f5d",
            "85b42ef3372b445cb3fd89f23802cf5f"
          ]
        },
        "id": "epwA58D1sEIv",
        "outputId": "b0b4e3dc-5897-4837-b702-b354cd73c207"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84184d5ee24d4f1b9763d000b9951c31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/6.33k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff06aac71e324cac8aeb17e642b55c4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "menyo20k_mt.py:   0%|          | 0.00/4.64k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38ea4c9e2de34c06a72dc1ca34ee03b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.49M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "452cb13c175944e29d88c16f3ad5808d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/850k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "710810670a484ee3844b43e787e39b1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d03863462d043ee87770f3cae7f2648",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/10070 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f164902e60743aba2927f80085299ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/3397 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50b56bcbd3194cdb8f8c3060aa12e21e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/6633 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English-Yoruba language pair II downloaded!\n"
          ]
        }
      ],
      "source": [
        "# English-Yoruba\n",
        "selected_languages = [\"yo\"]\n",
        "\n",
        "if \"yo\" in selected_languages:\n",
        "    try:\n",
        "        menyo_en_yo = load_dataset(\"UdS-LSV/menyo20k_mt\", trust_remote_code = True)\n",
        "        print(\"English-Yoruba language pair II downloaded!\")\n",
        "    except Exception as e:\n",
        "        print(\"Failed to download English-Yoruba:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBRXB-QEsECn"
      },
      "source": [
        "## **Qualitative and Quantitative Examination of Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sP_fn47_KhD"
      },
      "source": [
        "The following is a check-list to examine each dataset:\n",
        "\n",
        "1. Splits\n",
        "2. Features/columns\n",
        "3. Format\n",
        "4. Missing row\n",
        "5. Check internal usaga of language pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw8QvOLuCwW4"
      },
      "source": [
        "### **Splits Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpROvuCBAZX1"
      },
      "outputs": [],
      "source": [
        "# Check splits\n",
        "def print_split_info(name, dataset):\n",
        "    print(f\"\\n📊 Dataset: {name}\")\n",
        "\n",
        "    if isinstance(dataset, DatasetDict):\n",
        "        for split_name, split in dataset.items():\n",
        "            print(f\"  ➤ Split: {split_name} | Rows: {split.num_rows}\")\n",
        "    elif isinstance(dataset, Dataset):\n",
        "        print(f\"  ➤ Single split | Rows: {dataset.num_rows}\")\n",
        "    else:\n",
        "        print(\"❌ Unrecognized dataset type.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXGZYUTUAfLg",
        "outputId": "2dd38ab2-ff20-476c-e02e-b4e5b91cd151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 Dataset: Opus100: English-Yoruba Language Pair\n",
            "  ➤ Split: train | Rows: 10375\n",
            "\n",
            "📊 Dataset: Menyo: English-Yoruba Language Pair II\n",
            "  ➤ Split: train | Rows: 10070\n",
            "  ➤ Split: validation | Rows: 3397\n",
            "  ➤ Split: test | Rows: 6633\n"
          ]
        }
      ],
      "source": [
        "print_split_info(\"Opus100: English-Yoruba Language Pair\", opus_en_yo)\n",
        "print_split_info(\"Menyo: English-Yoruba Language Pair II\", menyo_en_yo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "339LSrt-CzqX"
      },
      "source": [
        "### **Features/Columns/Schema Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8JngOza_9R1"
      },
      "outputs": [],
      "source": [
        "# Check schema/column names using just the train split\n",
        "def print_dataset_features(datasets_with_names):\n",
        "    \"\"\"\n",
        "    Prints the .features of multiple Hugging Face datasets with names.\n",
        "\n",
        "    Args:\n",
        "        datasets_with_names (list of tuples): List of (dataset, name) pairs.\n",
        "    \"\"\"\n",
        "    for dataset, name in datasets_with_names:\n",
        "        print(f\"\\n📘 Features for: {name}\")\n",
        "        print(dataset.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2PbhGxesD-O",
        "outputId": "c8ba4312-8141-4065-8912-61a59b875e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📘 Features for: Opus EN-YO\n",
            "{'translation': Translation(languages=['en', 'yo'], id=None)}\n",
            "\n",
            "📘 Features for: Menyo EN-YO II\n",
            "{'translation': Translation(languages=('en', 'yo'), id=None)}\n"
          ]
        }
      ],
      "source": [
        "print_dataset_features([\n",
        "    (opus_en_yo['train'], \"Opus EN-YO\"),\n",
        "    (menyo_en_yo['train'], \"Menyo EN-YO II\")\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg6fv3ljsD7-"
      },
      "source": [
        "### **NLLB-Format-Compatibility Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aBzZIbQosD6b",
        "outputId": "25eece10-6a8f-4f6d-d771-4361bcbafaa8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n{\\n  \"translation\": {\\n    \"source language\": \"source sentence\",\\n    \"target language\": \"target sentence\"\\n  }\\n}\\n'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The NLLB model expects the following format:\n",
        "\n",
        "\"\"\"\n",
        "{\n",
        "  \"translation\": {\n",
        "    \"source language\": \"source sentence\",\n",
        "    \"target language\": \"target sentence\"\n",
        "  }\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VZCgVEwsD4E"
      },
      "outputs": [],
      "source": [
        "# Confirm dataset format\n",
        "\n",
        "def is_nllb_format(dataset, lang_pair=None, name=\"Unnamed\"):\n",
        "    \"\"\"\n",
        "    Checks if a Hugging Face dataset follows NLLB-style format.\n",
        "\n",
        "    Args:\n",
        "        dataset: Hugging Face dataset to inspect.\n",
        "        lang_pair: Tuple (source_lang, target_lang), e.g., (\"en\", \"yo\")\n",
        "        name: Name for logging\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 Checking NLLB format for: {name}\")\n",
        "    passed = True\n",
        "\n",
        "    for i, example in enumerate(dataset.select(range(min(10, len(dataset))))):  # check first 10 examples\n",
        "        if \"translation\" not in example:\n",
        "            print(f\"❌ Missing 'translation' field at index {i}\")\n",
        "            passed = False\n",
        "            break\n",
        "        if not isinstance(example[\"translation\"], dict):\n",
        "            print(f\"❌ 'translation' is not a dict at index {i}\")\n",
        "            passed = False\n",
        "            break\n",
        "        if lang_pair:\n",
        "            src, tgt = lang_pair\n",
        "            if src not in example[\"translation\"] or tgt not in example[\"translation\"]:\n",
        "                print(f\"❌ Missing expected lang codes {src}/{tgt} at index {i}\")\n",
        "                passed = False\n",
        "                break\n",
        "            if not example[\"translation\"][src] or not example[\"translation\"][tgt]:\n",
        "                print(f\"❌ Empty values for {src}/{tgt} at index {i}\")\n",
        "                passed = False\n",
        "                break\n",
        "        elif len(example[\"translation\"]) != 2:\n",
        "            print(f\"⚠️ Unexpected number of languages in 'translation' at index {i}: {example['translation'].keys()}\")\n",
        "            passed = False\n",
        "            break\n",
        "\n",
        "    if passed:\n",
        "        print(\"✅ Format is NLLB-compatible.\")\n",
        "    else:\n",
        "        print(\"❗ Not NLLB-compatible.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKY7bYL0sD12",
        "outputId": "61c5c43b-c4a9-4ded-a922-a9c19652aeff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Checking NLLB format for: Opus EN-YO\n",
            "✅ Format is NLLB-compatible.\n",
            "\n",
            "🔍 Checking NLLB format for: MENYO EN-IG\n",
            "✅ Format is NLLB-compatible.\n"
          ]
        }
      ],
      "source": [
        "is_nllb_format(opus_en_yo['train'], lang_pair=(\"en\", \"yo\"), name=\"Opus EN-YO\")\n",
        "is_nllb_format(menyo_en_yo['train'], lang_pair=(\"en\", \"yo\"), name=\"MENYO EN-IG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNijpKsUsDyF"
      },
      "source": [
        "### **Check Missing Row**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRfQs3GgsDui"
      },
      "outputs": [],
      "source": [
        "def check_missing_rows_all_splits(dataset_dict, name, src_lang=None, tgt_lang=None):\n",
        "    \"\"\"\n",
        "    Checks for missing or invalid rows across all splits in a DatasetDict.\n",
        "\n",
        "    Args:\n",
        "        dataset_dict (DatasetDict): The dataset with multiple splits.\n",
        "        name (str): Dataset name for reporting.\n",
        "        src_lang (str): Source language key (e.g., 'en').\n",
        "        tgt_lang (str): Target language key (e.g., 'yo').\n",
        "    \"\"\"\n",
        "    for split_name, split_dataset in dataset_dict.items():\n",
        "        total = len(split_dataset)\n",
        "        missing = 0\n",
        "\n",
        "        for row in split_dataset:\n",
        "            try:\n",
        "                if \"translation\" in row:\n",
        "                    trans = row[\"translation\"]\n",
        "                    src = trans.get(src_lang, \"\").strip() if src_lang else \"\"\n",
        "                    tgt = trans.get(tgt_lang, \"\").strip() if tgt_lang else \"\"\n",
        "                else:\n",
        "                    src = row.get(src_lang, \"\").strip()\n",
        "                    tgt = row.get(tgt_lang, \"\").strip()\n",
        "\n",
        "                if not src or not tgt or len(src) <= 1 or len(tgt) <= 1:\n",
        "                    missing += 1\n",
        "            except Exception:\n",
        "                missing += 1\n",
        "\n",
        "        print(f\"🔍 {name} ({split_name}): {missing} missing / {total} total rows\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn8hyABDsDsc",
        "outputId": "1b8a4daf-fdd3-451a-b0ec-392cab56936d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Opus EN-YO (train): 5 missing / 10375 total rows\n",
            "🔍 Menyo EN-YO II (train): 0 missing / 10070 total rows\n",
            "🔍 Menyo EN-YO II (validation): 0 missing / 3397 total rows\n",
            "🔍 Menyo EN-YO II (test): 0 missing / 6633 total rows\n"
          ]
        }
      ],
      "source": [
        "# Run checks\n",
        "check_missing_rows_all_splits(opus_en_yo, \"Opus EN-YO\", src_lang=\"en\", tgt_lang=\"yo\")\n",
        "check_missing_rows_all_splits(menyo_en_yo, \"Menyo EN-YO II\", src_lang=\"en\", tgt_lang=\"yo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LY848DGsDqA"
      },
      "source": [
        "### **Check Internal Usage of Language Pairs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIQzqprIsDeQ"
      },
      "outputs": [],
      "source": [
        "def preview_dataset_rows(dataset, name, src_lang=None, tgt_lang=None, n=3):\n",
        "    \"\"\"\n",
        "    Prints the first `n` rows of a dataset, showing raw string content using repr().\n",
        "\n",
        "    Args:\n",
        "        dataset: Hugging Face Dataset object\n",
        "        name (str): Dataset name for display\n",
        "        src_lang (str): Source language key\n",
        "        tgt_lang (str): Target language key\n",
        "        n (int): Number of rows to preview\n",
        "    \"\"\"\n",
        "    print(f\"\\n📘 Preview for: {name}\")\n",
        "    for i in range(min(n, len(dataset))):\n",
        "        row = dataset[i]\n",
        "        try:\n",
        "            if \"translation\" in row:\n",
        "                src = row[\"translation\"].get(src_lang, \"\")\n",
        "                tgt = row[\"translation\"].get(tgt_lang, \"\")\n",
        "            else:\n",
        "                src = row.get(src_lang, \"\")\n",
        "                tgt = row.get(tgt_lang, \"\")\n",
        "            print(f\"{i+1}. {src_lang}: {repr(src)}\")\n",
        "            print(f\"   {tgt_lang}: {repr(tgt)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"{i+1}. ❌ Error reading row {i}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpxM5m5vsDNE",
        "outputId": "20e362da-4b39-4fd4-c6ae-8aafa0b77a5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📘 Preview for: Opus EN-YO\n",
            "1. en: 'Mozilla (HTML)'\n",
            "   yo: 'Mozilla (HTML)'\n",
            "2. en: 'Workspace Switcher Preferences'\n",
            "   yo: 'Àwọn ìkúndùǹ Ìjánu-ìsún Ààyè-iṣẹ́'\n",
            "3. en: 'Set'\n",
            "   yo: 'Dí'\n",
            "\n",
            "📘 Preview for: Menyo EN-YO II\n",
            "1. en: 'Unit 1: What is Creative Commons?'\n",
            "   yo: '\\ufeffÌdá 1: Kín ni Creative Commons?'\n",
            "2. en: 'This work is licensed under a Creative Commons Attribution 4.0 International License.'\n",
            "   yo: 'Iṣẹ́ yìí wà lábẹ́ àṣẹ Creative Commons Attribution 4.0 International License.'\n",
            "3. en: 'Creative Commons is a set of legal tools, a nonprofit organization, as well as a global network and a movement — all inspired by people’s willingness to share their creativity and knowledge, and enabled by a set of open copyright licenses.'\n",
            "   yo: 'Creative Commons jẹ́ àwọn ọ̀kan-ò-jọ̀kan ohun-èlò ajẹmófin, iléeṣẹ́ àìlérèlórí, àti àjọ àwọn ènìyàn eléròǹgbà kan náà kárí àgbáńlá ayé— tí í ṣe ìmísí àwọn ènìyànkan tí ó ní ìfẹ́ tinútinú láti pín àwọn iṣẹ́-àtinúdá àti ìmọ̀ wọn èyí tí ó ní àtìlẹ́yìn àwọn ọ̀kan-ò-jọ̀kan àṣẹ ìṣísílẹ̀-gbangba-wálíà fún àtúnlò.'\n"
          ]
        }
      ],
      "source": [
        "# Show first 3 rows of each dataset\n",
        "preview_dataset_rows(opus_en_yo['train'], \"Opus EN-YO\", src_lang=\"en\", tgt_lang=\"yo\")\n",
        "preview_dataset_rows(menyo_en_yo['train'], \"Menyo EN-YO II\", src_lang=\"en\", tgt_lang=\"yo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ignb7_4wsDJu"
      },
      "source": [
        "## **Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M_FHykxsDHg"
      },
      "source": [
        "Before we clean, here are some highlight of observations in the examination stage:\n",
        "\n",
        "1. Opus100 English-Yoruba Language Pair\" (`opus_en_yo`) has just one split with less than 11k rows. Too small for the task at hand. We add Menyo...dataset.\n",
        "2. Missing rows\n",
        "  * Opus EN-YO (train)has 5 missing rows  \n",
        "  We eliminate missing rows in this stage.\n",
        "3. Menyo EN-YO II contains BOM text.Remove BOM text `\\ufeffÌdá`.\n",
        "\n",
        "  Unicode BOM (Byte Order Mark)` is invisible when printed, but it pollutes the text internally. Models treat it as a real character → causing:\n",
        "  * Garbage tokens during tokenization\n",
        "  * Poor fine-tuning\n",
        "  * Lower translation quality This must be eradicated to avoid errors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y__pI6DfsC2s"
      },
      "source": [
        "### **Clear Missing Rows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0DyAamasC0J"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "def clean_missing_rows(dataset_dict, src_lang=None, tgt_lang=None):\n",
        "    \"\"\"\n",
        "    Removes missing/invalid rows across all splits in a DatasetDict.\n",
        "\n",
        "    Args:\n",
        "        dataset_dict (DatasetDict): The dataset with splits (e.g. train, test, validation).\n",
        "        src_lang (str): Source language key (e.g., 'en').\n",
        "        tgt_lang (str): Target language key (e.g., 'yo').\n",
        "\n",
        "    Returns:\n",
        "        DatasetDict: Cleaned dataset with bad rows removed.\n",
        "    \"\"\"\n",
        "    cleaned_splits = {}\n",
        "\n",
        "    for split_name, split_dataset in dataset_dict.items():\n",
        "        def is_valid(row):\n",
        "            try:\n",
        "                if \"translation\" in row:\n",
        "                    src = row[\"translation\"].get(src_lang, \"\").strip()\n",
        "                    tgt = row[\"translation\"].get(tgt_lang, \"\").strip()\n",
        "                else:\n",
        "                    src = row.get(src_lang, \"\").strip()\n",
        "                    tgt = row.get(tgt_lang, \"\").strip()\n",
        "                return bool(src and tgt and len(src) > 1 and len(tgt) > 1)\n",
        "            except Exception:\n",
        "                return False\n",
        "\n",
        "        print(f\"🧹 Cleaning split: {split_name}...\")\n",
        "        cleaned_split = split_dataset.filter(is_valid)\n",
        "        cleaned_splits[split_name] = cleaned_split\n",
        "        print(f\"✅ {len(cleaned_split)} rows retained from {len(split_dataset)}\")\n",
        "\n",
        "    return DatasetDict(cleaned_splits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "bf561421a98046c3aa1c91036196ef2b",
            "9bde72f93a0a4d378fa474d885127302",
            "b661bbb1a4444dc2b3409b4b479f9b00",
            "5caf18de2d0344638a5ede763c4be0b4",
            "1658ae45ae11417c9fec7b6b1ff50bea",
            "1cfce3adf09341f8a81d01825d4adaf6",
            "c7838e4f591046f3877f3032f542ae4a",
            "6ad55ca49ff048f98e59d3833b817255",
            "9f5466bbdf0d4beca2ab650c74fe3a5a",
            "1336062736bf41628f175603fe8f7718",
            "acd0cbd53b0e4612beeda970cfb025d2",
            "afc0c14e8bf14f5095f053b5cdf0b6bc",
            "a2dabcd9f17f4cc3bf8a5fab6602832d",
            "66bf49c591af456cb0d11eb57ce684f7",
            "285dccf6bad94711b8f2255e221d9ca1",
            "01f33789fa5447c3abdef97b9e12df29",
            "e0e87583a5c6480795e80a6a2172c4f8",
            "cece97daaa28438d89c8e046183b10da",
            "6e84c98921174efba4ee7f1e1158afa8",
            "4e48843be4e644ce9cf9e2ef5115ce78",
            "01e1fb9a506f4c50a31e732e2dda4d52",
            "f9e0c5b2af824d48bce86f834e2b7e08",
            "fc1f5a6586624527ab42c1e5ee2c608d",
            "ec051c7ac4ce4864885148401f8b84c3",
            "5224eeae53c74df3b20f823077e9fa5e",
            "b6f673af80044cf587bb55abbd0ccb0a",
            "62e925d476db4047accf6d2276b0aad8",
            "dd1b9c44460e4f298dfdd1a3e85f0462",
            "9f780450a067483ea7ddaad126cad919",
            "b923872f333540e3be5ab5300b61919f",
            "dfe8d3e6498148c0b8711a0cb2fd0983",
            "a058e915c2e84d0a8b443eb1355b18c2",
            "efc466a36a7e45f8ae560bd758ce2227",
            "cf50ff7f494644caa13496ed5ecdc22d",
            "9fe11996ecaf48e0a13aba1b9ed8cf8a",
            "68b96bf605f342f7824209fddbdd0d40",
            "2f7753bfb4c84206a52c24760ad2b599",
            "6c897d85c0dc46129e7fb2619bdc1c5b",
            "ddab6d4c6b334f2cb8e57d246068c07a",
            "3b0fdb78c4a842fc80022a3e6db5055a",
            "df92d66ee3b142a280f9d3d49014cdcb",
            "c8931745beb145d7a9f3106c8f3d695f",
            "a14350fabb8c4e838468b825449bcec9",
            "785bebc818af481fb20919633f32dfe4"
          ]
        },
        "id": "KSbD4cVFsCxX",
        "outputId": "c1f55e3b-776a-4dd7-b4bb-221b0a885029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧹 Cleaning split: train...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf561421a98046c3aa1c91036196ef2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/10375 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 10370 rows retained from 10375\n",
            "🧹 Cleaning split: train...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afc0c14e8bf14f5095f053b5cdf0b6bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/10070 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 10070 rows retained from 10070\n",
            "🧹 Cleaning split: validation...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc1f5a6586624527ab42c1e5ee2c608d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/3397 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 3397 rows retained from 3397\n",
            "🧹 Cleaning split: test...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf50ff7f494644caa13496ed5ecdc22d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/6633 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 6633 rows retained from 6633\n"
          ]
        }
      ],
      "source": [
        "opus_en_yo_clean = clean_missing_rows(opus_en_yo, src_lang=\"en\", tgt_lang=\"yo\")\n",
        "menyo_clean = clean_missing_rows(menyo_en_yo, src_lang=\"en\", tgt_lang=\"yo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGxClR9dsCvc"
      },
      "source": [
        "### **Remove BOM Text from Menyo Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ac070d5f09374e2398fb0a60c1599a75",
            "4fb85f42c7314f05bab4925bd0fb1d9a",
            "fcb46f4d037a4503840efafb08b2c84a",
            "fd5f83481bfd41ce812f3abf672b5e0d",
            "6e5851c389ec4905a98c68a52221faf9",
            "c0d6bd3b08034814a369960a66288cf5",
            "3bdbe5ef7ec54a46925405d09d18b5ec",
            "6f0d4d369beb417c94d7021f4e7ecbf1",
            "182115b4eea249048e707f94de244dd3",
            "b5e777f8101c4e5089afa2635e5fd67a",
            "283ae89584bb42ed985b46ea4fc38fc4",
            "f155e563a647416e9846099d07f44999",
            "0187145c4df146d5b7afe87c5ee4d134",
            "6a3a79407d9642c3b18e8fc5ac6b97e4",
            "5f335f4f56ea498d94f1f9535331f034",
            "148a6dbdd951406eb8b10700d2bb8123",
            "cb3e8bc478c7470d8e3e59042aed11ff",
            "d47b984602b7474e97156bdce750eb76",
            "9f612e4022f74626be539d0cc6731061",
            "bad0201199a14c4aa6ecde79cee23758",
            "40da02cbdebd4dc69292f1881afcb51a",
            "08cca9750ca044d3ac37aed088c5a72c",
            "d5ccd06fc9734145b2ac61f5da69f201",
            "4c495f771de84d129f5dbce9e4d1e10d",
            "850eba0e62ce4c109d16ecb7d1f6490b",
            "844c2c66447f4899b6f5f1a32a347b9b",
            "8e84f7e199334db3b3d92bcbb8f69b91",
            "040ba5784d09411ab43e31fc2928e81a",
            "48ddbc43a28c4c61bae62fecf87f4ad9",
            "3c61435cff7c40a7a003afd9780a009e",
            "a347562594264d0991a0f0a416ccd802",
            "373feeeae6eb477f92d21d07fa7943e0",
            "405b12f33906474bb5a92bf7772c5e40"
          ]
        },
        "id": "PJ9o93WcsCsz",
        "outputId": "115aba0d-624c-4815-d291-d91c2b142df3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac070d5f09374e2398fb0a60c1599a75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10070 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f155e563a647416e9846099d07f44999",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3397 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5ccd06fc9734145b2ac61f5da69f201",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6633 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define cleaning function\n",
        "def remove_bom(example):\n",
        "    translation = example[\"translation\"]\n",
        "    cleaned_translation = {\n",
        "        \"yo\": translation[\"yo\"].replace(\"\\ufeff\", \"\") if \"yo\" in translation else None,\n",
        "        \"en\": translation[\"en\"].replace(\"\\ufeff\", \"\") if \"en\" in translation else None,\n",
        "    }\n",
        "    return {\"translation\": cleaned_translation}\n",
        "\n",
        "# Apply cleaning to all splits\n",
        "for split in [\"train\", \"validation\", \"test\"]:\n",
        "    if split in menyo_en_yo:\n",
        "        menyo_en_yo[split] = menyo_en_yo[split].map(remove_bom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqVUeqJAsCqe",
        "outputId": "541c0ead-13b2-4de8-b8a9-b5ce7a731a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'translation': {'en': 'Unit 1: What is Creative Commons?', 'yo': 'Ìdá 1: Kín ni Creative Commons?'}}\n",
            "{'translation': {'en': 'We prepare the saddle, and the goat presents itself; is it a burden for the lineage of goats?', 'yo': 'A di gàárì sílẹ̀ ewúrẹ́ ń yọjú; ẹrù ìran rẹ̀ ni?'}}\n",
            "{'translation': {'en': 'Pending the time she would finally pack and go, everybody should be content with eating just anything.', 'yo': 'Títí di ìgbà tí ó máa fi kó ẹrù rẹ̀ lọ pátápátá, kí oníkálùkù ní ìtẹ́lọ̀rùn pẹ̀lú ohunkóhun tó bá rí jẹ.'}}\n",
            "✅ BOM characters removed from dataset.\n"
          ]
        }
      ],
      "source": [
        "# Check\n",
        "print(menyo_en_yo['train'][0])\n",
        "print(menyo_en_yo['validation'][0])\n",
        "print(menyo_en_yo['test'][0])\n",
        "print(\"✅ BOM characters removed from dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghLvHPs7IavA"
      },
      "source": [
        "## **Standardize Feature Schema**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFJaXeoxIk28"
      },
      "outputs": [],
      "source": [
        "# Define consistent translation\n",
        "\n",
        "translation_features = Features({\n",
        "    \"translation\": Translation(languages=(\"en\", \"yo\"))\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "0090eb8101294beba928a5e5f0c28c22",
            "a5231f46a83c445eaf8056fb56eef57e",
            "22001fdfa7fe46d5a2ae5259db02e54f",
            "b180f5df007a4a28ba295f520a369fef",
            "099403f6bc5b42cbb770b249841cf5c7",
            "67d03c6a81a945e5b49a9cfd03d8567a",
            "1cf104e715b345929d7a9438e86430d2",
            "8afcd3b6ce5545ce8db807bc889bc4db",
            "427dd6a8c8894972b2c90c5063dfb171",
            "70a40c08eeb3424ca429f54aa65dd2ab",
            "b3c3aaffb4f74987869ec53e534b51eb",
            "955535b7188a4bd995a0d04e897fd048",
            "8fb2a25c0fb540ebb8964c8496cbc72a",
            "0be258c58adc4a64816d6f1252c0d895",
            "3e53ad2d5b334f119deff3515e2745d0",
            "96db6cd0284e46a295a7bfc5bf0c58d6",
            "1a4d401a1fa94bb38e86bddf31957b7b",
            "0104c50900934f90acf628df8ffc142c",
            "e9478075db1f4b84a79fe4b0004cbfea",
            "86b6d3d69bc8447f83e952a009dac2ac",
            "e359b724741049329d1c9cfafe1a6cbf",
            "c0f500fc124f450fa37844da597c3f43",
            "f86c8703c4a5412e914862282832844d",
            "9d66a8b725144ba9a422ad1c5d661302",
            "a34570186b2447c3ad9886a2a4513af5",
            "95138958a3084d13a734c8c1294fd041",
            "afeeed4bdfe840c9ba55833338c15360",
            "2935c603202c48fca86b6730cfe45562",
            "538adc0f437f45e982eaf90837ccf3b3",
            "d817aed5f8bd466281cebca3083cf4ef",
            "ca312262f0d04e04b6c06ed9c848b01c",
            "240cf505a2e34034862748ab59fc192e",
            "16bc0a84454e4f1dbebd1e704ab8d7ae",
            "7d273420c98f4bcba24c9674493fe798",
            "7ee2bdcbc9c04f80ad417556b799978c",
            "f65ff594e0fd49d5ba2370cbc1c77ccf",
            "2e7f93f39b174a29babd50eb7cecf2e2",
            "84476b0351b34dddbb2077e12f6793cf",
            "db571a0514154726b9349af8ad4cb1e1",
            "159dd4defb3b49ab87f2ec8b57a8184c",
            "97946c92076d4fd1b5deb7daf19a3dce",
            "dda5611a51ce486c9204658ac26e39a1",
            "bb1bde4438e74ee084584aa440645581",
            "5f2c3720153f4b96b57814b265857f0e"
          ]
        },
        "id": "sfjekM2LIvG5",
        "outputId": "d7ca55f8-6873-4563-a08e-d2b5b86a6fc5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0090eb8101294beba928a5e5f0c28c22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/10370 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "955535b7188a4bd995a0d04e897fd048",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/10070 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f86c8703c4a5412e914862282832844d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/3397 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d273420c98f4bcba24c9674493fe798",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/6633 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Prepare dataset list to combine\n",
        "datasets_to_concat = [opus_en_yo_clean, menyo_clean]\n",
        "\n",
        "# Cast all splits in all datasets to ensure schema alignment\n",
        "for i in range(len(datasets_to_concat)):\n",
        "    for split in datasets_to_concat[i]:\n",
        "        datasets_to_concat[i][split] = datasets_to_concat[i][split].cast(translation_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN-BeWt2ex-5"
      },
      "source": [
        "## **Concatenate Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkAKWVlVe_wV",
        "outputId": "cb813408-c61b-4463-de5f-08d5eaf7b45e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: 20440 examples\n",
            "validation: 3397 examples\n",
            "test: 6633 examples\n"
          ]
        }
      ],
      "source": [
        "def concatenate_yo_datasets(datasets_dicts):\n",
        "    splits = [\"train\", \"validation\", \"test\"]\n",
        "    combined = {}\n",
        "\n",
        "    for split in splits:\n",
        "        # Only include datasets that have this split\n",
        "        split_datasets = [ds[split] for ds in datasets_dicts if split in ds]\n",
        "        combined[split] = concatenate_datasets(split_datasets)\n",
        "\n",
        "    return DatasetDict(combined)\n",
        "\n",
        "# Combine datasets\n",
        "datasets_to_concat = [opus_en_yo_clean, menyo_clean]\n",
        "yoruba_dataset = concatenate_yo_datasets(datasets_to_concat)\n",
        "\n",
        "# Check number of rows\n",
        "for split in yoruba_dataset:\n",
        "    print(f\"{split}: {len(yoruba_dataset[split])} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niiPXmaBl3DP",
        "outputId": "15ab1c43-4afe-4409-b412-c551ec09a446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'translation': Translation(languages=['en', 'yo'], id=None)}\n"
          ]
        }
      ],
      "source": [
        "# Check\n",
        "print(yoruba_dataset[\"train\"].features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjeAJdzEsCgU",
        "outputId": "5da2e67d-0a69-43a7-a882-07f1211aa4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧪 Split: train\n",
            "train\n",
            "{'translation': {'en': 'Workspace Switcher Preferences', 'yo': 'Àwọn ìkúndùǹ Ìjánu-ìsún Ààyè-iṣẹ́'}}\n",
            "\n",
            "🧪 Split: validation\n",
            "validation\n",
            "{'translation': {'en': 'You have been crowned a king, and yet you make good-luck charms; would you be crowned God?', 'yo': 'A fi ọ́ jọba ò ń ṣàwúre o fẹ́ jẹ Ọlọ́run ni?'}}\n",
            "\n",
            "🧪 Split: test\n",
            "test\n",
            "{'translation': {'en': 'She knew how best she was going to take care of herself and Tinu.', 'yo': 'Ó mọ bí ó ṣe má a tọ́jú ara rẹ̀ àti Tinú.'}}\n"
          ]
        }
      ],
      "source": [
        "# Inspect examples from each split\n",
        "for split in [\"train\", \"validation\", \"test\"]:\n",
        "    print(f\"\\n🧪 Split: {split}\")\n",
        "    print([split][0])\n",
        "    print(yoruba_dataset[split][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxThvG09sCPX"
      },
      "source": [
        "Everything looks fine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXznBXbhsCM1"
      },
      "source": [
        "## **Save Dataset to Disc**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "59cae25954d148fe8c7218953b23f7a0",
            "e49f9407398b4b538aeea565febd752d",
            "d559b49994cd4fb89f7de21853dfe103",
            "68f807127ee346c8bd8f751dbc60cdb9",
            "5a9756ba5429419ba563ea777297e579",
            "04f98869223e4d9b89bdbedf52d7ad9d",
            "6633af37aae8465ebc726fd6f260cb5a",
            "b342ff0b25c9463a9cdbb90e1368e67d",
            "f31ad2c1fba3458c98a5065d25037944",
            "08335195747943f781cd4c6930494b1f",
            "b071a06d8b8b453b832aa5bf94ea79e6",
            "25a1ff1f1fbd46f0acae6bcc5784f7be",
            "e9dcca402a9e4e8b9a135d78fd6e5a13",
            "54cc5d941a4e44d488f19fd0638b3376",
            "389bbba282304fa3ae6b92602171973d",
            "b46c6e207bd4420198c90464fdcc5b5a",
            "66abb968c3ac47878d8b612978a52dab",
            "b019af6dde4041e2b7342f6b10e8b387",
            "38b826f045cc4c349393051fec020586",
            "173968d800b14afead43968ff0faecbd",
            "edfb1bd1244b491ba8a01716825e54cc",
            "bb4164c8f62b4938b2f65f297ccc3326",
            "46912652afd8467d86f153126c385967",
            "43e8deb069ce4286af754fcf4c1d0af1",
            "ce35921b58bf48e49fa55011facd62b5",
            "2f4b73d236e24cdd822ebdfb3750c552",
            "aaf40a29db42433b89e219b7520331d1",
            "a390dd189b6c472f883c0b5093fb290c",
            "f80d139c1b724dab9687d06c92eba987",
            "d318f7e4c6774ff3885a993380c2af5f",
            "91ef4a0c2ea54755aa4d6475eddacf8a",
            "73d6773126ea458086ef1c0e227d3506",
            "ebff02b0225c4420a3bade6200da0e60"
          ]
        },
        "id": "CrkWvHwksCKn",
        "outputId": "b41e6114-a654-4d57-da65-67d17f37ca67"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59cae25954d148fe8c7218953b23f7a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/20440 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25a1ff1f1fbd46f0acae6bcc5784f7be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/3397 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46912652afd8467d86f153126c385967",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/6633 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset saved to: /content/drive/MyDrive/Colab Notebooks/NLLB_200/En-Yo_LaTn/CombinedYorubaDataset\n"
          ]
        }
      ],
      "source": [
        "save_path = f\"{save_dir}/CombinedYorubaDataset\"\n",
        "yoruba_dataset.save_to_disk(save_path)\n",
        "print(f\"✅ Dataset saved to: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6M7yEkAsCGx"
      },
      "source": [
        "## **Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8jUXsqsp8wB"
      },
      "source": [
        "### **Load Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "43b3ce78fd0a46748290727f9c73025d",
            "ac5858ae6a72468eac549cb83f94644b",
            "c88951ceaa6f483db37049ee78ad22a7",
            "03c107dc2898415c80eace7741979ffc",
            "d18dd3929af9440aa1a2ed306206b0b5",
            "f738a4d761784fb2a621c3d96597459c",
            "8785455ebe0747bcafa4d74948729cb1",
            "947435b5e9e54c62baa0fcc8742cc91e",
            "ae1404c94cfe4c99944213126153b105",
            "a18fb55d4c7c46828082c1f5eeca72c0",
            "9e0542a61ab24d9fab3b1418a1fb55c1",
            "915f462f2c8740a7b089f26d4427fc56",
            "bc7734c08c4b443cb75e07e1aa4d3de1",
            "4604c1ca1afe4e78ad0d514fcc1c66fb",
            "7057b29f7d254f6d8b7738251d39cb88",
            "4057646afc694fe9af27d2cf56ac1767",
            "2f3a026d073f4ff3b86506dc101f81da",
            "12c49581640c42bbb09f287029bc998c",
            "15ceafb4a9714450991be2551b2dc1fe",
            "81480da779014b78b2ea266025cad01f",
            "63ce925c535a45a6b64a2ca24e852510",
            "ce8e035c521a48cc81dfcd37b13e6be0",
            "cf3343cd25d543c4b2bab7b1b28ac9df",
            "822ca86019004309860defd64faddbad",
            "3f8df361cc694277b29105e55f51021f",
            "0e2b09487edf4d9c85cd9d7c150b8fd6",
            "8668997db7994baf8caadcdd569fc6ab",
            "b547a9f032894079a8bfa5a58731b0aa",
            "ad146cc56c844ee797640023782246c6",
            "4a617ba4d2cc49cfa60430caab242384",
            "c5e1ddfe66554042aacb163179f62690",
            "d7c3efe8ce884b5da4d943f398ae9fa2",
            "ee0e0294c9654ab89bf957ea2377d6eb",
            "5e1d25766cfb49fb840471e26b154699",
            "9fe57dab470e4b86bf7bbc466456ac57",
            "d0b8bd5f30a141a4b6e3c294c035fdb4",
            "8b76daf240394ccaa6d5eb258029f26a",
            "d647b4b2f8ed4bd9b8769c58764f2c89",
            "230abd17a2a043a8b8f878ac89932490",
            "835dfb9ab331407f91308d9ebeac9027",
            "71a2b5db464e409d8aa3c9479b4bf3eb",
            "29ccadc03cff47a7b8d1c87d44a55e39",
            "81c0be5e14d54307b5f7c6b3bed6ef68",
            "c8444f3bddf94310919b276cc2186d6c"
          ]
        },
        "id": "AXEK4cgUp8tN",
        "outputId": "d747b928-7318-4932-c6f8-08dbe55860ca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43b3ce78fd0a46748290727f9c73025d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "915f462f2c8740a7b089f26d4427fc56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf3343cd25d543c4b2bab7b1b28ac9df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e1d25766cfb49fb840471e26b154699",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_checkpoint = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "tokenizer.padding_side = \"right\" #  proper for attention mask alignment and decoder positioning for encoder-decoder model like NLLB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emM8wGTBp8p6"
      },
      "source": [
        "### **Preprocess**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1vp_iykp8K9"
      },
      "outputs": [],
      "source": [
        "# Isolate data splits\n",
        "train_dataset = yoruba_dataset[\"train\"]\n",
        "val_dataset = yoruba_dataset[\"validation\"]\n",
        "test_dataset = yoruba_dataset[\"test\"]\n",
        "\n",
        "\n",
        "# Set the target language for NLLB tokenizer globally\n",
        "tokenizer.src_lang = \"eng_Latn\"\n",
        "tokenizer.tgt_lang = \"yor_Latn\"\n",
        "\n",
        "def preprocess(example):\n",
        "    source = example.get(\"translation\", {}).get(\"en\", None)\n",
        "    target = example.get(\"translation\", {}).get(\"yo\", None)\n",
        "\n",
        "    if not source or not target:\n",
        "        return {\n",
        "            \"input_ids\": [],\n",
        "            \"attention_mask\": [],\n",
        "            \"labels\": []\n",
        "            }\n",
        "\n",
        "    # Add source language prefix for NLLB-style\n",
        "    input_text = f\">>yor_Latn<< {source}\"\n",
        "\n",
        "    # Tokenize source and target using set lang codes\n",
        "    model_inputs = tokenizer(\n",
        "        input_text,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    # Target tokenization works correctly if tgt_lang is already set\n",
        "    target_inputs = tokenizer(\n",
        "        target,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    model_inputs[\"labels\"] = target_inputs[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "4efd248498704370ac613754fb5a8d24",
            "06c9fd57e92246a898e3a1723bc18735",
            "2d23024311124e688edd59528db0699a",
            "3ecc457814d64f08b6f9752bf7f96e4d",
            "a77a2bd8ba76416ca6501ec7fcd816d0",
            "07dee357c54c4923aadf694e85017aca",
            "e473f92d810d41e29e99742d98a5b203",
            "6884ae561e854b379d25211139b1e36c",
            "9e2417a5a7094f83935dd42b83eb5eed",
            "a7107cdbba8c4f179e75236b8317b0f6",
            "ba201ef04b454afa9ea4de4ac49541d0",
            "f5d77e303dd941a6862583d058eb0ea1",
            "ca1fa70377b6470d924fb539a54a160e",
            "03eee99bbd91421b84ed3ff383a9726b",
            "4f3b8e2ac8dd4b078502bbbd4436dede",
            "5af09fdcd52046f3a0f1ee8be17f4416",
            "eb3ac647f6a448cc9682a9ce51bf100f",
            "ab204f1629504a10aded78713de93072",
            "83f672c05efa44aba421a90a33430308",
            "da095024f61e4599908a37a70cffe096",
            "7a3c05fee87243f992b8fa0cd74bee06",
            "4bcaedbdd1ef430ba53c81ebbd03e8de",
            "e46c9e57f9a14ac489239886b799ad9e",
            "134d7f3f4ba348d2b2075a2aea24cf09",
            "04ace3d2a2ab4270bfee78fdd7b581f8",
            "45e3a1a5eb164a42a5864163f737d182",
            "3016f8b8713f4ef68e4839c66331a173",
            "05d34b4db26d4eed84794a46b0a5c300",
            "2c131e78dcb24f88a11a9385d932c2cf",
            "3153babc116d4c75917514bd768f3a8b",
            "6d8f65598a24441792eec8714d1858dd",
            "407a10afb729440394c775770f29321d",
            "91b4fd8dd4cd47ec8cdb28272d384360",
            "2ea507a1382e4e338797ff9d8ac5b157",
            "5e770d68d75046bcb8ae8caf51e9ac96",
            "3f55309b6e0741928c2366d17188c688",
            "240934e179134195a4c8f8a4c4dfc206",
            "a4fccb0996ec4195b00985a86d6409f3",
            "2593e29fe066461db3c8038675434c38",
            "e4ba7e5835094791ae099cd721e79bdb",
            "32c32da7e88b40eeb6b39a5fe98803be",
            "72eb6dd2b0ef4c36bdfd3036ea75ae14",
            "41db2bb6ee1349348a9102bfb669ca97",
            "25d8865948524b50826b1e53545b9088",
            "413c745701524c8fb668c9424f314f29",
            "debf8c9d6faf4edf8230eb77632dd3b4",
            "440dd9e5b4b3445fa40460f05b455856",
            "7af6f41b2f804f2f91380124b49160d2",
            "dd7913653b344ef8b7506537a60d86f1",
            "fdc81dc83a964f4da5660de7b83af95f",
            "48021019517b40b3b8397aba345843fc",
            "5dfd14d75f5d46f3aa1686582ff985d7",
            "75e0ff88745d4730b52c591edd32dee2",
            "3e2b825e67d74825b1929788be6abd5f",
            "59519efd205d40db87293537eec46f30",
            "bd39ccd257a342a7965c73d6bbbb2595",
            "f7225beb8bdb468d8f34c83090171950",
            "1ee70f9d65aa4a6bada22ddf00babcfc",
            "f8a395c181864fcc8bc6d34eef9790dc",
            "e4b282d0e0c24257897e85b780e0a5d8",
            "ea8ff5e6ac80460783b267629ec8e0f5",
            "99ad57d782fb437ab8322c30da12673b",
            "9bc36a6c94594d0992ffc57747ea3fed",
            "8cd42748f37c49e7b2beedca7066e6a8",
            "c8b479927402496d9d98737c06beae64",
            "0092b05a55e240e2bc388103720e57bf"
          ]
        },
        "id": "rlpgDiFBXhcp",
        "outputId": "50410a13-e89c-4378-8261-7a37f3d13a2f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4efd248498704370ac613754fb5a8d24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train set (num_proc=4):   0%|          | 0/20440 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5d77e303dd941a6862583d058eb0ea1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/20440 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e46c9e57f9a14ac489239886b799ad9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing val set (num_proc=4):   0%|          | 0/3397 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ea507a1382e4e338797ff9d8ac5b157",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/3397 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "413c745701524c8fb668c9424f314f29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing test set (num_proc=4):   0%|          | 0/6633 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd39ccd257a342a7965c73d6bbbb2595",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/6633 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Map Preprocessing on all splits\n",
        "\n",
        "train_tokenized = train_dataset.map(\n",
        "    preprocess,\n",
        "    remove_columns=[\"translation\"],\n",
        "    num_proc=4,  # Optional: use multiple processes\n",
        "    desc=\"Tokenizing train set\"\n",
        ").filter(lambda example: example.get(\"labels\") is not None)\n",
        "\n",
        "val_tokenized = val_dataset.map(\n",
        "    preprocess,\n",
        "    remove_columns=[\"translation\"],\n",
        "    num_proc=4,\n",
        "    desc=\"Tokenizing val set\"\n",
        ").filter(lambda example: example.get(\"labels\") is not None)\n",
        "\n",
        "test_tokenized = test_dataset.map(\n",
        "    preprocess,\n",
        "    remove_columns=[\"translation\"],\n",
        "    num_proc=4,\n",
        "    desc=\"Tokenizing test set\"\n",
        ").filter(lambda example: example.get(\"labels\") is not None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MSZL1Txp7_R",
        "outputId": "7860f0f4-c536-43f9-a585-f0197a3b2429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [256047, 20545, 256198, 57642, 179399, 104, 234972, 248161, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [256047, 179399, 104, 234972, 248161, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "# Check a sample from tokenized data to confirm tokenization\n",
        "print(train_tokenized[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "LcPpKA-Op78N",
        "outputId": "3a64649a-0010-4093-a854-ef9bbe4b536b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n{\\n    'translation': {\\n        'en': 'Mozilla (HTML)',         # The source sentence (English)\\n        'yo': '<Yoruba> Mozilla (HTML)' # The target sentence (Yoruba, with language tag)\\n    },\\n    'input_ids': [256047, 179399, 104, 234972, 248161, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], # Tokenized input\\n    'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], # Mask for padding tokens\\n    'labels': [256047, 179399, 104, 234972, 248161, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], # Tokenized target (no language tag)\\n    'detected_tgt_lang': 'yor' # Detected target language\\n}\\n\""
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The strcture above is interpreted as:\n",
        "\n",
        "\"\"\"\n",
        "{\n",
        "    'translation': {\n",
        "        'en': 'Mozilla (HTML)',         # The source sentence (English)\n",
        "        'yo': '<Yoruba> Mozilla (HTML)' # The target sentence (Yoruba, with language tag)\n",
        "    },\n",
        "    'input_ids': [256047, 179399, 104, 234972, 248161, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], # Tokenized input\n",
        "    'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], # Mask for padding tokens\n",
        "    'labels': [256047, 179399, 104, 234972, 248161, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], # Tokenized target (no language tag)\n",
        "    'detected_tgt_lang': 'yor' # Detected target language\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSS3vb437RVL",
        "outputId": "103da030-147a-4f9c-b46f-71d54aef60bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 20440\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(train_tokenized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM2dqks9p7zG"
      },
      "source": [
        "## **Fine-Tune NLLB**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHFNAuXBp7wZ"
      },
      "source": [
        "### **Configure BitsAndBytes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRktXaopp7tQ"
      },
      "outputs": [],
      "source": [
        "# BitsAndBytes parameters\n",
        "################################################################################\n",
        "use_4bit = True # 4-bit precision on base model loading\n",
        "bnb_4bit_compute_dtype = torch.float16 # compute datatype for 4-bit base model\n",
        "bnb_4bit_quant_type = \"nf4\" # quantization type\n",
        "use_nested_quant = False # activate nested quantization for 4-bit base models (double quantization)\n",
        "\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "5cd5acdb64c94392b948beda32f20298",
            "15f8d59099fa4708a2d350630a8a2e3c",
            "67473c29e10a4379a56265c668590104",
            "92e8f3e412ab4585afe8987caf4fdabe",
            "35290839eeb340148fd2a7a3d867a871",
            "119ac42ba03e453ca7b2046cc72aa134",
            "588f1e34f57148b2bf16f7aece356ffd",
            "24caf2c9266a457c817aa7ce41f0dd71",
            "bf21816fa1e94d86b6c18084e656c5e7",
            "b665ba360f974e6497932e6f56067263",
            "a6c5cd67d1aa4ff4b0a561c0ae9c8220",
            "2ea5e96ee8954adcbf612745135f4506",
            "9c7e690c87a243199e94d36bc3f13dea",
            "cc900f34dbe0493fbb6b4ee7b5e4d905",
            "ef8b6cf8347f48ee92181bd1261016d7",
            "58277e5f2b9841a79ca7d87409c57898",
            "2c56a5834db54344a596e6ab6068ed5a",
            "50ffd522c2834c05b21d40b3a96fea4f",
            "09a03abca56d4095ae6c09c6597ac47a",
            "196910a4f5274d4581452b1dfad0334f",
            "e0fbd2ae1e5248aeb0f6f75e87e822fa",
            "d41a9624138b45139cd816ab0e1caab6",
            "2af7d777d9bb48058da5c95d0a321269",
            "f54cd144f2c34deba082aeeff5077e85",
            "ee1d66fc79fb432cab29fcb86dd1516c",
            "a22ce7912ca746228cf9934f051de948",
            "edbc4f8ea1b24faba47695b698e6501c",
            "0409802e4e8e433cb823bc9d197eaa36",
            "1e1e8c63db194b1b95ebb5a73ca4956f",
            "950f8630911048ef99bbe05ca7fc226c",
            "b901acdb824749c1846618c8a6157b23",
            "c956e4ec9bda4f4d96a761f1feae46a9",
            "38895141ebbd4c35885eea738f1baabd",
            "c104d5e1d1d44037ae5f4b553638284d",
            "1cef6e4b4e1941b5be3385dfb4e40c4a",
            "62e6f78e281b4788ac87eee4b7339d14",
            "60ca5df8d8214bb99b5052ff96660ed0",
            "e3347df8eefa4752b268d0aa8a9b52b5",
            "fae8114a0f2942a2bfa8d55dba91c5b6",
            "ef5967bcd9b444f293ced8360b4e1fbc",
            "a8225610e81d4a35b7a912d90a164615",
            "3a5a1dbc32024807a46057ed6a08c977",
            "82a8311394474b0a8517d5f471f89b8b",
            "89627681b2184432afebb8727d1ccf25"
          ]
        },
        "id": "Je9N6UmhsCAA",
        "outputId": "a1b16645-1cc2-4772-a4f3-1593d5470983"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cd5acdb64c94392b948beda32f20298",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ea5e96ee8954adcbf612745135f4506",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2af7d777d9bb48058da5c95d0a321269",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c104d5e1d1d44037ae5f4b553638284d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint,\n",
        "                                              device_map=\"auto\",\n",
        "                                              low_cpu_mem_usage=True,  # Explicitly set to avoid the warning\n",
        "                                              quantization_config=bnb_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S4n34njN6AF"
      },
      "source": [
        "### **Test Model with Zero Shot Inferencing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "jhElREp_N5f8",
        "outputId": "5f0080ab-2855-4edb-cbad-b5d89ad27f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔤 English: The weather today is very pleasant.\n",
            "🌍 Yoruba: Ojú ọjọ́ òde òní dára gan-an.\n",
            "CPU times: user 1.17 s, sys: 631 ms, total: 1.8 s\n",
            "Wall time: 5.89 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# 🌍 Define source & target languages (ISO 639-3 codes)\n",
        "src_lang = \"eng_Latn\"\n",
        "tgt_lang = \"yor_Latn\"\n",
        "\n",
        "# ✏️ Example input sentence in English\n",
        "input_sentence = \"The weather today is very pleasant.\"\n",
        "\n",
        "# 🔡 Tokenize with language codes\n",
        "inputs = tokenizer(\n",
        "    input_sentence,\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512\n",
        ")\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "# ✨ Set language tokens\n",
        "inputs[\"forced_bos_token_id\"] = tokenizer.convert_tokens_to_ids(tgt_lang)\n",
        "tokenizer.src_lang = src_lang\n",
        "\n",
        "# 🔁 Run inference\n",
        "with torch.no_grad():\n",
        "    output_tokens = model.generate(\n",
        "        **inputs,\n",
        "        max_length=128,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "# 🗣️ Decode result\n",
        "translated_text = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)[0]\n",
        "print(f\"🔤 English: {input_sentence}\")\n",
        "print(f\"🌍 Yoruba: {translated_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_ByOm0WsB95"
      },
      "source": [
        "### **Setup Model with LoRA (PEFT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFqF8EjfsB7k"
      },
      "outputs": [],
      "source": [
        "# Set up LoRA config with target_modules\n",
        "lora_config = LoraConfig(\n",
        "    r = 8,  # Rank of the decomposition\n",
        "    lora_alpha = 32,  # Scaling factor for LoRA updates\n",
        "    lora_dropout = 0.05,  # Dropout rate for LoRA\n",
        "    task_type = TaskType.SEQ_2_SEQ_LM,  # Sequence-to-sequence task\n",
        "    bias = 'none',\n",
        "    target_modules = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],  # Attention layers (query, value, key, output)\n",
        ")\n",
        "\n",
        "# Apply LoRA adapters to the model\n",
        "model_with_lora = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wrLctjFsB5V",
        "outputId": "e2bae69a-c033-42db-a4a0-cc6dad1390d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,769,472 || all params: 616,843,264 || trainable%: 0.2869\n"
          ]
        }
      ],
      "source": [
        "# Check trainable parameters\n",
        "model_with_lora.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYBKR9rJsB2B"
      },
      "source": [
        "### **Prepare DataCollator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7fgOW3EsBzf"
      },
      "outputs": [],
      "source": [
        "# Instantiate the data collator for sequence-to-sequence tasks\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer,\n",
        "                                       model = model_with_lora,\n",
        "                                       padding = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Ps9qrwsBx0"
      },
      "source": [
        "### **Define Seq2SeqTrainingArguments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEdtHMzusBvZ"
      },
      "outputs": [],
      "source": [
        "# Training arguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    eval_strategy = \"epoch\",  # Evaluate after every epoch\n",
        "    logging_dir = f\"{save_dir}/logs\",  # Directory for storing logs\n",
        "    logging_strategy = \"steps\",  # Log every N steps\n",
        "    logging_steps = 25,  # Log every 25 steps\n",
        "    save_strategy = \"epoch\",  # Save model after every epoch\n",
        "    save_total_limit = 3,  # Keep only the latest 3 checkpoints\n",
        "    per_device_train_batch_size = 4,  # Batch size per device for training\n",
        "    per_device_eval_batch_size = 4,  # Batch size per device for evaluation\n",
        "    gradient_accumulation_steps = 2,  # Accumulate gradients for 2 steps before updating weights\n",
        "    num_train_epochs = 3,  # Total number of epochs\n",
        "    predict_with_generate = True,  # Predict with generate\n",
        "    weight_decay = 0.01,  # Weight decay\n",
        "    lr_scheduler_type = \"linear\",  # Linear learning rate scheduler\n",
        "    optim = \"paged_adamw_32bit\",  # Optimizer to use\n",
        "    learning_rate = 2e-5,  # Initial learning rate\n",
        "    eval_steps = 500, # run validation every 500 steps\n",
        "    fp16 = True,  # Use mixed precision training (not recommended for faster training on GPUs, especially A100 GPUs)\n",
        "    load_best_model_at_end = True,  # Load the best model at the end based on evaluation metric\n",
        "    metric_for_best_model = \"eval_loss\",  # Metric to monitor for the best model (e.g., BLEU score for translation)\n",
        "    greater_is_better = False,  # Higher BLEU metric scores are better\n",
        "    report_to = \"none\",  # Use TensorBoard for logging\n",
        "    disable_tqdm = False,  # Enable or disable tqdm (progress bar)\n",
        "    save_steps = 500,  # Save model checkpoints every 500 steps\n",
        "    label_names = [\"labels\"],  # Name of the label column in the dataset\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7IOQD149N4S"
      },
      "source": [
        "### **Compute Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzYXaeC49N0m"
      },
      "outputs": [],
      "source": [
        "# metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# def compute_metrics(eval_preds):\n",
        "#     preds, labels = eval_preds\n",
        "#     decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "#     result = metric.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n",
        "#     return {\"bleu\": result[\"score\"]}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC7Kcd3e9NyL"
      },
      "source": [
        "### **Training Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oR-8S_C9Nte"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model_with_lora,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized.select(range(min(len(val_tokenized), 2000))),\n",
        "    data_collator=data_collator,\n",
        "    #compute_metrics=compute_metrics  # compute BLEU\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW_SqH4u9Nru"
      },
      "source": [
        "### **Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "34MRpJpr9NhC",
        "outputId": "50c7b59e-e754-4730-e8a7-8840b4bc66ba"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training starts at 1747760575.7574346\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4699' max='7665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4699/7665 38:39 < 24:24, 2.03 it/s, Epoch 1.84/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.672500</td>\n",
              "      <td>6.007836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7665' max='7665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7665/7665 1:04:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.672500</td>\n",
              "      <td>6.007836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.391500</td>\n",
              "      <td>5.964256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>6.547900</td>\n",
              "      <td>5.956226</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ends at 1747764421.0577939\n",
            "Training time: 1h 4m 5s\n"
          ]
        }
      ],
      "source": [
        "# Compute total training time\n",
        "start_time = time.time()\n",
        "print(f\"Training starts at {start_time}\")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training ends at {end_time}\")\n",
        "\n",
        "total_seconds = end_time - start_time\n",
        "hours = int(total_seconds // 3600)\n",
        "minutes = int((total_seconds % 3600) // 60)\n",
        "seconds = int(total_seconds % 60)\n",
        "\n",
        "print(f\"Training time: {hours}h {minutes}m {seconds}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60KJ7ufX9NfX"
      },
      "source": [
        "## **Save Model and Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-D2ibw39Ndx",
        "outputId": "e3167c01-7beb-4fa9-f253-90777f4475b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab Notebooks/NLLB_200/En-Yo_LaTn/En-Yo_FT_model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/NLLB_200/En-Yo_LaTn/En-Yo_FT_model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/NLLB_200/En-Yo_LaTn/En-Yo_FT_model/sentencepiece.bpe.model',\n",
              " '/content/drive/MyDrive/Colab Notebooks/NLLB_200/En-Yo_LaTn/En-Yo_FT_model/added_tokens.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/NLLB_200/En-Yo_LaTn/En-Yo_FT_model/tokenizer.json')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.save_model(f\"{save_dir}/En-Yo_FT_model\")\n",
        "tokenizer.save_pretrained(f\"{save_dir}/En-Yo_FT_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdvOafqm8YfR"
      },
      "source": [
        "## **Push to Hugging Face**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tgAKc9i8Ycr",
        "outputId": "7f6ce39a-6082-44f9-b56a-ea207ca0fd76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# !pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5DLNK7w8YaG",
        "outputId": "41207177-b4d8-4e9a-81c0-00dac93e89ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "The token `DibiaCorp` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `DibiaCorp`\n"
          ]
        }
      ],
      "source": [
        "# !huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229,
          "referenced_widgets": [
            "aa5138a3b0cf46f7a7130a46fb90a696",
            "643eddd5d3714a6ca7f5f7f760da8d00",
            "59698af8f68b476d9168891f1eb7f88f",
            "b78d7d5cd9a54346a095ebe612478b51",
            "83fb6ecae44f45f1a5c418db4c205161",
            "8c54d6b74af34891a5c8407e73746d4a",
            "0dd25465709440c282fd16d93b7eb934",
            "0823cf3c354f49228b003c967227b289",
            "f1d25bb6be00409982d63e9994dc22ea",
            "fab4faa6511a4860b36be5c039d55fdd",
            "3d37f7f8aaa8408d80fa809a78b07598",
            "1d1d65f4e93644fbb44bf4700ae5951d",
            "2545388d1db248578d2702f73594b86b",
            "c2e456239bd44bd3a1a3589d43c53e9c",
            "ef10690264204d6f9e12fca37df4fef8",
            "df454fd0efa1459c9b193cb780aba373",
            "b12fb02c3c4b4e698b64f2ace00d4329",
            "54f1576617a14459929f12c7743b44a1",
            "93b563b69cf24be8b96e67ccff4dc5ee",
            "9f380a6bd0294849a4e1a0e8e4784556",
            "8ee599b6176542168514966b8fcae554",
            "2a82b8bd41b644bfa705a120aae1c57c",
            "a1f67af51a7149e0818597594604c103",
            "395f764a65e04f959bdd8a7b3f3096cf",
            "189453b2f29d413da70799089fae511a",
            "9b310f082b1b46ff8071d41e53d274d9",
            "430551133164485e8ceb3c348efa8c86",
            "e62d0e4dd154463386d88b1a141c420c",
            "6c3dc5e4e7c54c88b1b654a4bf28b723",
            "758d1b179b31401f8ccdbc9bf1a44e21",
            "e814e6705ee145bfa74870c1a76377c2",
            "c0bc6a095aee4a1993f6853e7464f8aa",
            "632ceed4c93345b5a78a113df9f0dd4b",
            "7f088caccc76491fb86bccf630158017",
            "5a9c9fec2d5447e7a6b7fa6b241ff662",
            "9cb0cfb0746943d4b566b597654d4b57",
            "23106e0c60424a81a8206ac574e52faa",
            "4cab75d80352418c83bc8b9f139f95b7",
            "7252a62a039d41e48962cc5009d64b77",
            "d7ead92823d749f0942b2efb75511c40",
            "2d91a78859744b089b3894b78c9f6192",
            "2ec9c048c9b548bf93a177cbb424a0f4",
            "7d82c63e9d824685bcad63717d880c51",
            "4c7b3c5146c4403a8b49f89fc781403e",
            "04d7b965514c4fada7313dec16c40ffc",
            "471cc6a36c4346d8af885061d41a1951",
            "822234b271ac4a43a687b02e80402b9a",
            "6fd7857e0b8649bc83c5cc3d7f9936d8",
            "730e8bec77a14748952e991180dce4ef",
            "4e0eb3074a7f48bab44eb3c0beee684b",
            "8db0a36f9a434f7a90c4ade929918178",
            "868eeb78b8274bfaaad24e385449bd45",
            "1b592ca1906b43c6ba2de01653e93bf4",
            "3ad703b951b24e498ff570a7d43c7303",
            "aba1ad5eddac467281ee880256f5bcb6"
          ]
        },
        "id": "jSuQrzx_8YXO",
        "outputId": "1ae77d22-115e-45a8-bb48-1a069b1620ae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa5138a3b0cf46f7a7130a46fb90a696",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/7.11M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d1d65f4e93644fbb44bf4700ae5951d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1f67af51a7149e0818597594604c103",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f088caccc76491fb86bccf630158017",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04d7b965514c4fada7313dec16c40ffc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/32.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/drakensberg85/English-Yoruba_NLLB_FT_model/commit/9cc03e33b1f9fe0dcc2c12b2fbd594326c88f228', commit_message='Upload tokenizer', commit_description='', oid='9cc03e33b1f9fe0dcc2c12b2fbd594326c88f228', pr_url=None, repo_url=RepoUrl('https://huggingface.co/drakensberg85/English-Yoruba_NLLB_FT_model', endpoint='https://huggingface.co', repo_type='model', repo_id='drakensberg85/English-Yoruba_NLLB_FT_model'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from huggingface_hub import HfApi, HfFolder\n",
        "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# # Define repo details\n",
        "# repo_name = \"drakensberg85/English-Yoruba_NLLB_FT_model\"\n",
        "# model_path = f\"{save_dir}/En-Yo_FT_model\"\n",
        "\n",
        "# # # Upload using transformers\n",
        "# AutoModelForSeq2SeqLM.from_pretrained(model_path).push_to_hub(repo_name)\n",
        "# AutoTokenizer.from_pretrained(model_path).push_to_hub(repo_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_DWECZL8YUA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI3p6I-d9NZH"
      },
      "source": [
        "## **TensorBoard Logging and Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcKoftke9NXZ"
      },
      "outputs": [],
      "source": [
        "# writer = SummaryWriter(f\"{save_dir}/logs\")\n",
        "# print(\"Training complete. View metrics using TensorBoard:\")\n",
        "# print(f\"Run this in Colab terminal: tensorboard --logdir={save_dir}/logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZQqrrLb9NTd"
      },
      "outputs": [],
      "source": [
        "# %reload_ext tensorboard\n",
        "# %tensorboard --logdir \"/content/drive/MyDrive/Colab Notebooks/NLLB_600M/En-Yo_LaTn/logs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igDlKhBK9NQb"
      },
      "source": [
        "## **Inference Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdRXyhpQw_-i",
        "outputId": "580b2d7b-f883-43d4-8884-1a59e43eda9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: I want to go home.\n",
            "Yoruba: Mo fẹ́ lọ sílé.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Use the correct model path\n",
        "model_path = f\"{save_dir}/En-Yo_FT_model\"\n",
        "\n",
        "# Load tokenizer and model from local files\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path, local_files_only=True)\n",
        "\n",
        "# Send model to appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Example sentence for translation\n",
        "english_sentence = \"I want to go home.\"\n",
        "source_sentence = f\">>yor_Latn<< {english_sentence}\"\n",
        "\n",
        "# Tokenize input and move to device\n",
        "inputs = tokenizer(source_sentence, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Generate translation\n",
        "with torch.no_grad():\n",
        "    output = model.generate(**inputs, max_length=128, num_beams=5, early_stopping=True)\n",
        "\n",
        "# Decode and print translation\n",
        "yoruba_translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(f\"English: {english_sentence}\")\n",
        "print(f\"Yoruba: {yoruba_translation}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Spj8CD8Uw_7b"
      },
      "source": [
        "## **Incorporating Chainlit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBI_xyl1w_4g",
        "outputId": "828ed073-3ec9-412f-b43e-8d97e686b8c4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import chainlit as cl\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "# Load model & tokenizer\n",
        "model_path = f\"{save_dir}/En-Yo_FT_model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "@cl.on_chat_start\n",
        "async def start():\n",
        "    await cl.Message(content=\"👋 Welcome! Type something in English and I'll translate it to Yoruba!\").send()\n",
        "\n",
        "@cl.on_message\n",
        "async def main(message: cl.Message):\n",
        "    input_text = f\">>yor_Latn<< {message.content}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Create an empty Chainlit message to stream into\n",
        "    response = cl.Message(content=\"\")\n",
        "    await response.send()\n",
        "\n",
        "    # Generate tokens step-by-step\n",
        "    output_tokens = model.generate(\n",
        "        **inputs,\n",
        "        max_length=128,\n",
        "        num_beams=1,  # Beam search disables streaming behavior\n",
        "        do_sample=False,\n",
        "        output_scores=False,\n",
        "        return_dict_in_generate=True\n",
        "    )\n",
        "\n",
        "    # Stream tokens (you can simulate streaming with a short delay per chunk if needed)\n",
        "    output_text = tokenizer.decode(output_tokens.sequences[0], skip_special_tokens=True)\n",
        "\n",
        "    # Simulate streaming (token-by-token)\n",
        "    for token in output_text.split():\n",
        "        response.content += token + \" \"\n",
        "        await response.update()\n",
        "\n",
        "    # Final update\n",
        "    await response.update()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mycaZysfw_o4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}